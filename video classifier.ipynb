{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g02_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g04_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g05_c01.avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    video_name\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g02_c01.avi\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c01.avi\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g04_c01.avi\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g05_c01.avi"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(r\"C:\\Users\\Manjith Reddy\\Desktop\\Test1\\trainlist.txt\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating a dataframe having video names\n",
    "train_video = pd.DataFrame()\n",
    "train_video['video_name'] = videos\n",
    "train_video = train_video[:-1]\n",
    "train_video.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    video_name\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c01.avi\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c01.avi\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c01.avi\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(r\"C:\\Users\\Manjith Reddy\\Desktop\\Test1\\testlist.txt\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating a dataframe having video names\n",
    "test_video = pd.DataFrame()\n",
    "test_video['video_name'] = videos\n",
    "test_video = test_video[:-1]\n",
    "test_video.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tags for train and test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tags for training videos\n",
    "train_video_tag = []\n",
    "for i in range(train_video.shape[0]):\n",
    "    train_video_tag.append(train_video['video_name'][i].split('/')[0])\n",
    "    \n",
    "train_video['tag'] = train_video_tag\n",
    "\n",
    "# creating tags for test videos\n",
    "test_video_tag = []\n",
    "for i in range(test_video.shape[0]):\n",
    "    test_video_tag.append(test_video['video_name'][i].split('/')[0])\n",
    "    \n",
    "test_video['tag'] = test_video_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g02_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g04_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g05_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    video_name             tag\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi  ApplyEyeMakeup\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g02_c01.avi  ApplyEyeMakeup\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c01.avi  ApplyEyeMakeup\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g04_c01.avi  ApplyEyeMakeup\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g05_c01.avi  ApplyEyeMakeup"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_video.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    video_name             tag\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c01.avi  ApplyEyeMakeup\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi  ApplyEyeMakeup\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c01.avi  ApplyEyeMakeup\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c01.avi  ApplyEyeMakeup\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi  ApplyEyeMakeup"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_video.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_video.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convertion of videos into frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [00:35<00:00,  9.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# storing the frames from training videos\n",
    "for i in tqdm(range(train_video.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = train_video['video_name'][i]\n",
    "    Tagfile = train_video['tag'][i]\n",
    "    cap = cv2.VideoCapture('C:\\\\Users\\\\Manjith Reddy\\\\Desktop\\\\Test1\\\\Data\\\\'+Tagfile+'\\\\'+videoFile.split(' ')[0].split('/')[1])   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    x=1\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate) == 0):\n",
    "            # storing the frames in a new folder named train_1\n",
    "            filename ='C:\\\\Users\\\\Manjith Reddy\\\\Desktop\\\\Test1\\\\train_1\\\\'+ videoFile.split('/')[1].split(' ')[0] +\"_frame%d.jpg\" % count\n",
    "            count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of images and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2485/2485 [00:00<00:00, 621443.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# getting the names of all the images\n",
    "images = glob(\"train_1/*.jpg\")\n",
    "train_image = []\n",
    "train_class = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    # creating the image name\n",
    "    train_image.append(images[i].split('\\\\')[1])\n",
    "    # creating the class of image\n",
    "    train_class.append(images[i].split('\\\\')[1].split('_')[1])\n",
    "    \n",
    "# storing the images and their class in a dataframe\n",
    "train_data = pd.DataFrame()\n",
    "train_data['image'] = train_image\n",
    "train_data['class'] = train_class\n",
    "\n",
    "# converting the dataframe into csv file \n",
    "train_data.to_csv('train_new.csv',header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_frame0.jpg</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_frame1.jpg</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_frame2.jpg</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_frame3.jpg</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_ApplyEyeMakeup_g01_c01.avi_frame4.jpg</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image           class\n",
       "0  v_ApplyEyeMakeup_g01_c01.avi_frame0.jpg  ApplyEyeMakeup\n",
       "1  v_ApplyEyeMakeup_g01_c01.avi_frame1.jpg  ApplyEyeMakeup\n",
       "2  v_ApplyEyeMakeup_g01_c01.avi_frame2.jpg  ApplyEyeMakeup\n",
       "3  v_ApplyEyeMakeup_g01_c01.avi_frame3.jpg  ApplyEyeMakeup\n",
       "4  v_ApplyEyeMakeup_g01_c01.avi_frame4.jpg  ApplyEyeMakeup"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_new.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2485/2485 [00:18<00:00, 131.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2485, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('train_1/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of video classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1988, 7, 7, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 7, 7, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(1988, 7*7*512)\n",
    "X_test = X_test.reshape(497, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the pixel values\n",
    "max = X_train.max()\n",
    "X_train = X_train/max\n",
    "X_test = X_test/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1988, 25088)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the video classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "\n",
    "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1988 samples, validate on 497 samples\n",
      "Epoch 1/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 2.9343 - accuracy: 0.0830 - val_loss: 2.7764 - val_accuracy: 0.2334\n",
      "Epoch 2/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 2.7093 - accuracy: 0.1519 - val_loss: 2.5409 - val_accuracy: 0.1871\n",
      "Epoch 3/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 2.5487 - accuracy: 0.1901 - val_loss: 2.4141 - val_accuracy: 0.2636\n",
      "Epoch 4/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 2.3807 - accuracy: 0.2430 - val_loss: 2.1699 - val_accuracy: 0.3058\n",
      "Epoch 5/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 2.2188 - accuracy: 0.2726 - val_loss: 1.9793 - val_accuracy: 0.3763\n",
      "Epoch 6/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 2.0285 - accuracy: 0.3390 - val_loss: 1.7465 - val_accuracy: 0.4527\n",
      "Epoch 7/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 1.8420 - accuracy: 0.3858 - val_loss: 1.4740 - val_accuracy: 0.5775\n",
      "Epoch 8/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 1.6094 - accuracy: 0.4623 - val_loss: 1.1538 - val_accuracy: 0.6620\n",
      "Epoch 9/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 1.3373 - accuracy: 0.5438 - val_loss: 0.8771 - val_accuracy: 0.7223\n",
      "Epoch 10/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 1.1387 - accuracy: 0.6031 - val_loss: 0.7217 - val_accuracy: 0.7887\n",
      "Epoch 11/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 0.9037 - accuracy: 0.6977 - val_loss: 0.5381 - val_accuracy: 0.8330\n",
      "Epoch 12/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 0.7233 - accuracy: 0.7555 - val_loss: 0.3838 - val_accuracy: 0.8773\n",
      "Epoch 13/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 0.6098 - accuracy: 0.7857 - val_loss: 0.3113 - val_accuracy: 0.9074\n",
      "Epoch 14/20\n",
      "1988/1988 [==============================] - 8s 4ms/step - loss: 0.4751 - accuracy: 0.8395 - val_loss: 0.2087 - val_accuracy: 0.9537\n",
      "Epoch 15/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 0.4083 - accuracy: 0.8662 - val_loss: 0.1455 - val_accuracy: 0.9779\n",
      "Epoch 16/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 0.3071 - accuracy: 0.9039 - val_loss: 0.1190 - val_accuracy: 0.9819\n",
      "Epoch 17/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 0.2596 - accuracy: 0.9185 - val_loss: 0.0971 - val_accuracy: 0.9799\n",
      "Epoch 18/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 0.2390 - accuracy: 0.9291 - val_loss: 0.0656 - val_accuracy: 0.9879\n",
      "Epoch 19/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 0.1872 - accuracy: 0.9391 - val_loss: 0.0557 - val_accuracy: 0.9899\n",
      "Epoch 20/20\n",
      "1988/1988 [==============================] - 7s 4ms/step - loss: 0.1470 - accuracy: 0.9633 - val_loss: 0.0506 - val_accuracy: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x165ef5bb8d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of our classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained weights\n",
    "model.load_weights('weight.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    video_name\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c01.avi\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c01.avi\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c01.avi\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(r\"C:\\Users\\Manjith Reddy\\Desktop\\Test1\\testlist.txt\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating a dataframe having video names\n",
    "test_video = pd.DataFrame()\n",
    "test_video['video_name'] = videos\n",
    "test_video = test_video[:-1]\n",
    "test_video.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tags for test videos\n",
    "test_video_tag = []\n",
    "for i in range(test_video.shape[0]):\n",
    "    test_video_tag.append(test_video['video_name'][i].split('/')[0])\n",
    "    \n",
    "test_video['tag'] = test_video_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi</td>\n",
       "      <td>ApplyEyeMakeup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    video_name             tag\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c01.avi  ApplyEyeMakeup\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi  ApplyEyeMakeup\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c01.avi  ApplyEyeMakeup\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c01.avi  ApplyEyeMakeup\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi  ApplyEyeMakeup"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_video.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the tags\n",
    "train = pd.read_csv('train_new.csv')\n",
    "y = train['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating predictions for test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "predict=[]\n",
    "actual=[]\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(test_video.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = test_video['video_name'][i]\n",
    "    Tagfile = test_video['tag'][i]\n",
    "    cap = cv2.VideoCapture('C:\\\\Users\\\\Manjith Reddy\\\\Desktop\\\\Test1\\\\Data\\\\'+Tagfile+'\\\\'+videoFile.split(' ')[0].split('/')[1])   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    x=1\n",
    "    # removing all other files from the temp folder\n",
    "    files = glob('test_1/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate) == 0):\n",
    "            # storing the frames of this particular video in temp folder\n",
    "            filename ='C:\\\\Users\\\\Manjith Reddy\\\\Desktop\\\\Test1\\\\test_1\\\\'+ videoFile.split('/')[1].split(' ')[0] +\"_frame%d.jpg\" % count\n",
    "            count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()\n",
    "    \n",
    "    images = glob(\"test_1/*.jpg\")\n",
    "    \n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        prediction_images.append(img)\n",
    "\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model.predict(prediction_images)\n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "    # predicting tags for each array\n",
    "    prediction = model.predict_classes(prediction_images)\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
    "    # appending the actual tag of the video\n",
    "    actual.append(videoFile.split('/')[1].split('_')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.91011235955057"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy of the predicted tags\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'BlowDryHair',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'BoxingPunchingBag',\n",
       " 'BodyWeightSquats',\n",
       " 'BandMarching',\n",
       " 'BoxingSpeedBag',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BabyCrawling',\n",
       " 'BabyCrawling',\n",
       " 'BabyCrawling',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BalanceBeam',\n",
       " 'Basketball',\n",
       " 'BalanceBeam',\n",
       " 'Basketball',\n",
       " 'BandMarching',\n",
       " 'BandMarching',\n",
       " 'BandMarching',\n",
       " 'BandMarching',\n",
       " 'BandMarching',\n",
       " 'Basketball',\n",
       " 'BalanceBeam',\n",
       " 'Basketball',\n",
       " 'Basketball',\n",
       " 'BaseballPitch',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Basketball',\n",
       " 'Basketball',\n",
       " 'Biking',\n",
       " 'Archery',\n",
       " 'BasketballDunk',\n",
       " 'BasketballDunk',\n",
       " 'BasketballDunk',\n",
       " 'BasketballDunk',\n",
       " 'BenchPress',\n",
       " 'BenchPress',\n",
       " 'BenchPress',\n",
       " 'BenchPress',\n",
       " 'BenchPress',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Billiards',\n",
       " 'Billiards',\n",
       " 'Billiards',\n",
       " 'Billiards',\n",
       " 'Billiards',\n",
       " 'BlowDryHair',\n",
       " 'BlowDryHair',\n",
       " 'BlowDryHair',\n",
       " 'BlowDryHair',\n",
       " 'BlowDryHair',\n",
       " 'Archery',\n",
       " 'BlowingCandles',\n",
       " 'BabyCrawling',\n",
       " 'BlowingCandles',\n",
       " 'BlowingCandles',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'Biking',\n",
       " 'BoxingPunchingBag',\n",
       " 'BodyWeightSquats',\n",
       " 'Bowling',\n",
       " 'Bowling',\n",
       " 'Bowling',\n",
       " 'Bowling',\n",
       " 'Bowling',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'Bowling',\n",
       " 'BoxingSpeedBag',\n",
       " 'BoxingSpeedBag',\n",
       " 'BabyCrawling']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyEyeMakeup',\n",
       " 'ApplyEyeMakeup',\n",
       " 'ApplyEyeMakeup',\n",
       " 'ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'Archery',\n",
       " 'Archery',\n",
       " 'Archery',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BabyCrawling',\n",
       " 'BabyCrawling',\n",
       " 'BabyCrawling',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BalanceBeam',\n",
       " 'BalanceBeam',\n",
       " 'BalanceBeam',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BandMarching',\n",
       " 'BandMarching',\n",
       " 'BandMarching',\n",
       " 'BandMarching',\n",
       " 'BaseballPitch',\n",
       " 'BaseballPitch',\n",
       " 'BaseballPitch',\n",
       " 'BaseballPitch',\n",
       " 'BaseballPitch',\n",
       " 'Basketball',\n",
       " 'Basketball',\n",
       " 'Basketball',\n",
       " 'Basketball',\n",
       " 'Basketball',\n",
       " 'BasketballDunk',\n",
       " 'BasketballDunk',\n",
       " 'BasketballDunk',\n",
       " 'BasketballDunk',\n",
       " 'BasketballDunk',\n",
       " 'BenchPress',\n",
       " 'BenchPress',\n",
       " 'BenchPress',\n",
       " 'BenchPress',\n",
       " 'BenchPress',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Biking',\n",
       " 'Billiards',\n",
       " 'Billiards',\n",
       " 'Billiards',\n",
       " 'Billiards',\n",
       " 'Billiards',\n",
       " 'BlowDryHair',\n",
       " 'BlowDryHair',\n",
       " 'BlowDryHair',\n",
       " 'BlowDryHair',\n",
       " 'BlowDryHair',\n",
       " 'BlowingCandles',\n",
       " 'BlowingCandles',\n",
       " 'BlowingCandles',\n",
       " 'BlowingCandles',\n",
       " 'BlowingCandles',\n",
       " 'BodyWeightSquats',\n",
       " 'BodyWeightSquats',\n",
       " 'BodyWeightSquats',\n",
       " 'BodyWeightSquats',\n",
       " 'BodyWeightSquats',\n",
       " 'Bowling',\n",
       " 'Bowling',\n",
       " 'Bowling',\n",
       " 'Bowling',\n",
       " 'Bowling',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingSpeedBag',\n",
       " 'BoxingSpeedBag',\n",
       " 'BoxingSpeedBag',\n",
       " 'BoxingSpeedBag']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
